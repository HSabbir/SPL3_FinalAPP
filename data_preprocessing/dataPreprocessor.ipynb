{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#https://medium.com/mlearning-ai/parsing-the-esc50-audio-dataset-with-tensorflow-2ad4ae96f6b0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "import math\n",
    "from utils import *\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "import librosa\n",
    "import scipy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "def getCleanSpeech(mozilla_basepath,val_dataset_size, dataframe_name, sep):\n",
    "    mozilla_metadata = pd.read_csv(os.path.join(mozilla_basepath, dataframe_name), sep=sep)\n",
    "    clean_files = mozilla_metadata['path'].values\n",
    "    np.random.shuffle(clean_files)\n",
    "    clean_files = [os.path.join(mozilla_basepath, 'clips', filename) for filename in clean_files]\n",
    "    if dataframe_name=='test.tsv':\n",
    "        return clean_files\n",
    "    clean_files = clean_files[:-val_dataset_size]\n",
    "    clean_val_files = clean_files[-val_dataset_size:]\n",
    "    return clean_files, clean_val_files"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def get_filenames_by_class_id(basepath,metadata):\n",
    "    class_ids = None\n",
    "    if class_ids is None:\n",
    "        class_ids = np.unique(metadata['classID'].values)\n",
    "\n",
    "    all_files = []\n",
    "    file_counter = 0\n",
    "    for c in class_ids:\n",
    "        per_class_files = metadata[metadata['classID'] == c][['slice_file_name', 'fold']].values\n",
    "        per_class_files = [os.path.join(basepath, 'audio', 'fold' + str(file[1]), file[0]) for file in per_class_files]\n",
    "        file_counter += len(per_class_files)\n",
    "        all_files.extend(per_class_files)\n",
    "\n",
    "    return all_files"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "def getNoisySpeech(urbansound_basepath, val_dataset_size, test=False):\n",
    "    urbansound_metadata = pd.read_csv(os.path.join(urbansound_basepath, 'metadata', 'UrbanSound8K.csv'))\n",
    "\n",
    "    urbansound_metadata.reindex(np.random.permutation(urbansound_metadata.index))\n",
    "    if test:\n",
    "        urbansound_train = urbansound_metadata[urbansound_metadata.fold == 10]\n",
    "        urbansound_train_filenames = get_filenames_by_class_id(urbansound_basepath,urbansound_train)\n",
    "        np.random.shuffle(urbansound_train_filenames)\n",
    "        return urbansound_train_filenames\n",
    "\n",
    "    else:\n",
    "\n",
    "        urbansound_train = urbansound_metadata[urbansound_metadata.fold != 10]\n",
    "\n",
    "        urbansound_train_filenames = get_filenames_by_class_id(urbansound_basepath,urbansound_train)\n",
    "    np.random.shuffle(urbansound_train_filenames)\n",
    "\n",
    "    urbansound_val = urbansound_train_filenames[-val_dataset_size:]\n",
    "    urbansound_train = urbansound_train_filenames[:-val_dataset_size]\n",
    "\n",
    "    return urbansound_train, urbansound_val"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "windowLength = 256\n",
    "config = {'windowLength': windowLength,\n",
    "          'overlap': round(0.25 * windowLength),\n",
    "          'fs': 16000,\n",
    "          'audio_max_duration': 0.8}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "mozilla_basepath = 'C:/Users/B989/Downloads/Compressed/cv-corpus-10.0-2022-07-04-bn/bn'\n",
    "urbansound_basepath = 'C:/Users/B989/OneDrive - Brain Station 23 Ltd/Documents/UrbanSound8K/UrbanSound8K'\n",
    "\n",
    "clean_train_filenames, clean_val_filenames = getCleanSpeech(mozilla_basepath,val_dataset_size=1000,dataframe_name ='train.tsv', sep='\\t')\n",
    "\n",
    "noise_train_filenames, noise_val_filenames = getNoisySpeech(urbansound_basepath,val_dataset_size=200)\n",
    "\n",
    "\n",
    "clean_test_filenames = getCleanSpeech(mozilla_basepath,val_dataset_size=1000,dataframe_name ='test.tsv', sep='\\t')\n",
    "\n",
    "noise_test_filenames = getNoisySpeech(urbansound_basepath,val_dataset_size=200, test=True)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "def read_audio(filepath, sample_rate, normalize=True):\n",
    "    audio, sr = librosa.load(filepath, sr=sample_rate)\n",
    "    if normalize is True:\n",
    "        div_fac = 1 / np.max(np.abs(audio)) / 3.0\n",
    "        audio = audio * div_fac\n",
    "    return audio, sr"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "def removeSilentFrames(audio):\n",
    "    trimed_audio = []\n",
    "    indices = librosa.effects.split(audio, hop_length=config.overlap, top_db=20)\n",
    "\n",
    "    for index in indices:\n",
    "        trimed_audio.extend(audio[index[0]: index[1]])\n",
    "    return np.array(trimed_audio)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "def cropAudio(audio):\n",
    "    audio_duration_secs = librosa.core.get_duration(audio, config.fs)\n",
    "\n",
    "    if config.audio_max_duration >= audio_duration_secs:\n",
    "        return audio\n",
    "\n",
    "    audio_duration_ms = math.floor(audio_duration_secs * config.fs)\n",
    "    duration_ms = math.floor(config.audio_max_duration * config.fs)\n",
    "    idx = np.random.randint(0, audio_duration_ms - duration_ms)\n",
    "    return audio[idx: idx + duration_ms]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def mixCleanNoisyAudio(clean_audio, noise_signal):\n",
    "    if len(clean_audio) >= len(noise_signal):\n",
    "        while len(clean_audio) >= len(noise_signal):\n",
    "            noise_signal = np.append(noise_signal, noise_signal)\n",
    "\n",
    "    ind = np.random.randint(0, noise_signal.size - clean_audio.size)\n",
    "\n",
    "    noiseSegment = noise_signal[ind: ind + clean_audio.size]\n",
    "\n",
    "    speech_power = np.sum(clean_audio ** 2)\n",
    "    noise_power = np.sum(noiseSegment ** 2)\n",
    "    noisyAudio = clean_audio + np.sqrt(speech_power / noise_power) * noiseSegment\n",
    "    return noisyAudio"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "def getSTFTspectrogram(audio, ffT_length):\n",
    "    window = scipy.signal.hamming(config.window_length, sym=False)\n",
    "    return librosa.stft(audio, n_fft=ffT_length, win_length=config.window_length, hop_length=config.overlap, window=window, center=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "def getPhase(clean_spectral_magnitude, clean_phase, noise_phase):\n",
    "    assert clean_phase.shape == noise_phase.shape, \"Shapes must match.\"\n",
    "    return clean_spectral_magnitude * np.cos(clean_phase - noise_phase)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "def audio_processing(clean_filename, noise_filenames):\n",
    "\n",
    "    clean_audio, _ = read_audio(clean_filename, config.fs)\n",
    "\n",
    "    clean_audio = removeSilentFrames(clean_audio)\n",
    "\n",
    "    noise_filename = np.random.choice(noise_filenames)\n",
    "\n",
    "    noise_audio, sr = read_audio(noise_filename,  config.fs)\n",
    "\n",
    "    noise_audio = removeSilentFrames(noise_audio)\n",
    "\n",
    "    clean_audio = cropAudio(clean_audio)\n",
    "\n",
    "    noiseInput = mixCleanNoisyAudio(clean_audio, noise_audio)\n",
    "\n",
    "    noise_spectrogram = getSTFTspectrogram(noiseInput)\n",
    "\n",
    "    noise_phase = np.angle(noise_spectrogram)\n",
    "\n",
    "    noise_magnitude = np.abs(noise_spectrogram)\n",
    "\n",
    "    clean_spectrogram = getSTFTspectrogram(clean_audio)\n",
    "\n",
    "    clean_phase = np.angle(clean_spectrogram)\n",
    "\n",
    "    clean_magnitude = np.abs(clean_spectrogram)\n",
    "\n",
    "    clean_magnitude = getPhase(clean_magnitude, clean_phase, noise_phase)\n",
    "\n",
    "    scaler = StandardScaler(copy=False, with_mean=True, with_std=True)\n",
    "    noise_magnitude = scaler.fit_transform(noise_magnitude)\n",
    "    clean_magnitude = scaler.transform(clean_magnitude)\n",
    "\n",
    "    return noise_magnitude, clean_magnitude, noise_phase"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "def prepare_input_features(stft_features, numSegments, numFeatures):\n",
    "    noisySTFT = np.concatenate([stft_features[:, 0:numSegments - 1], stft_features], axis=1)\n",
    "    stftSegments = np.zeros((numFeatures, numSegments, noisySTFT.shape[1] - numSegments + 1))\n",
    "\n",
    "    for index in range(noisySTFT.shape[1] - numSegments + 1):\n",
    "        stftSegments[:, :, index] = noisySTFT[:, index:index + numSegments]\n",
    "    return stftSegments\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "def create_tf_record(clean_filenames, *, prefix, subset_size):\n",
    "    counter = 0\n",
    "    for i in range(0, len(clean_filenames), subset_size):\n",
    "        tfrecord_filename = prefix + '_' + str(counter) + '.tfrecords'\n",
    "        if os.path.isfile(tfrecord_filename):\n",
    "            print(f\"Skipping {tfrecord_filename}\")\n",
    "            counter += 1\n",
    "            continue\n",
    "\n",
    "        writer = tf.io.TFRecordWriter(tfrecord_filename)\n",
    "        clean_filenames_sublist =clean_filenames[i:i + subset_size]\n",
    "\n",
    "        print(f\"Processing files from: {i} to {i + subset_size}\")\n",
    "        '''if parallel:\n",
    "            out = p.map(self.parallel_audio_processing, clean_filenames_sublist)\n",
    "        else:'''\n",
    "        out = [audio_processing(filename) for filename in clean_filenames_sublist]\n",
    "\n",
    "        for o in out:\n",
    "            noise_stft_magnitude = o[0]\n",
    "            clean_stft_magnitude = o[1]\n",
    "            noise_stft_phase = o[2]\n",
    "\n",
    "            noise_stft_mag_features = prepare_input_features(noise_stft_magnitude, numSegments=8, numFeatures=129)\n",
    "\n",
    "            noise_stft_mag_features = np.transpose(noise_stft_mag_features, (2, 0, 1))\n",
    "            clean_stft_magnitude = np.transpose(clean_stft_magnitude, (1, 0))\n",
    "            noise_stft_phase = np.transpose(noise_stft_phase, (1, 0))\n",
    "\n",
    "            noise_stft_mag_features = np.expand_dims(noise_stft_mag_features, axis=3)\n",
    "            clean_stft_magnitude = np.expand_dims(clean_stft_magnitude, axis=2)\n",
    "\n",
    "            for x_, y_, p_ in zip(noise_stft_mag_features, clean_stft_magnitude, noise_stft_phase):\n",
    "                y_ = np.expand_dims(y_, 2)\n",
    "                example = get_tf_feature(x_, y_, p_)\n",
    "                writer.write(example.SerializeToString())\n",
    "\n",
    "        counter += 1\n",
    "        writer.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping val_0.tfrecords\n"
     ]
    }
   ],
   "source": [
    "create_tf_record(clean_val_filenames, prefix='val', subset_size=2000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping train_0.tfrecords\n",
      "Skipping train_1.tfrecords\n",
      "Skipping train_2.tfrecords\n",
      "Skipping train_3.tfrecords\n"
     ]
    }
   ],
   "source": [
    "create_tf_record(clean_train_filenames ,prefix='train', subset_size=4000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping test_0.tfrecords\n",
      "Skipping test_1.tfrecords\n",
      "Skipping test_2.tfrecords\n",
      "Skipping test_3.tfrecords\n",
      "Skipping test_4.tfrecords\n",
      "Skipping test_5.tfrecords\n",
      "Skipping test_6.tfrecords\n",
      "Skipping test_7.tfrecords\n",
      "Skipping test_8.tfrecords\n"
     ]
    }
   ],
   "source": [
    "create_tf_record(clean_test_filenames, prefix='test', subset_size=1000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}